{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best CNN Model for ASL Recognition (28 classes)\n",
    "- 5 Convolutional Layers, 3 Pooling Layers, 1 Linear Layer, 1 Output Layer\n",
    "- ReLU Activation Functions\n",
    "- Batch normalization on all layers, dropout (p=0.4) on linear layers only\n",
    "- Training batch size of 64\n",
    "- Learning rate of 0.001\n",
    "- Convolutional Kernel: 5x5\n",
    "- Pooling kernel: 2x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Python 3.11.4\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchsummary\n",
    "import os\n",
    "import cv2\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import gc\n",
    "import datetime\n",
    "import sys\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in raw dataset, run pre-processing and convert image data to tensors.\n",
    "- Resize each image to 128x128 from 200x200\n",
    "- Adjust brightness and contrast randomly, convert all images to grayscale\n",
    "- Create horizontal flip of each image (1 new image)\n",
    "- Apply two random rotations for original image and two random rotations for flipped image (4 new images)\n",
    "- Total: 1 original image -> 6 processed images. So the original dataset size of 84000 turns to 504000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Pre-Processing -> Apply random contrast, saturation.  Flip horizontally once, then do 2 random rotations between -45 and 45 to flip and original (1 image becomes 6 images)\n",
    "base_path = r\"C:\\Users\\twinj\\OneDrive\\CAP5610_Project\"\n",
    "\n",
    "#unzip the images and prepare for data processing\n",
    "zip_path = os.path.join(base_path, \"asl_alphabet_train.zip\") #a zip files containing the 28 classes as folders of each letter\n",
    "extract_folder = os.path.join(base_path, \"extracted_imgs\")\n",
    "#create new folder for extracted files\n",
    "os.makedirs(extract_folder, exist_ok=True)\n",
    "#extract the files from the zipped folder to this new folder\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_folder)\n",
    "#path to new directory\n",
    "images_path = os.path.join(extract_folder, \"asl_alphabet_train\")\n",
    "image_folders = os.listdir(images_path)\n",
    "#print(image_folders)\n",
    "\n",
    "# Pre-allocate image_data to ensure memory is reserved\n",
    "SKIP_VAL = 1\n",
    "NUM_CLASSES= 28\n",
    "image_data= np.empty(((3000//SKIP_VAL)*NUM_CLASSES*6, 128, 128, 1), dtype=np.float16)\n",
    "print(\"RAM used to store image data: \" + str(sys.getsizeof(image_data) // (1024*1024)) + \" MB\")\n",
    "labels = []\n",
    "index = 0  # This will keep track of where you are in the array\n",
    "\n",
    "for i in range(len(image_folders)):  # only use every five images from raw dataset\n",
    "    gc.collect()\n",
    "    #print(\"Now loading in images from folder: \" + str(image_folders[i]) + \", time: \" + str(datetime.datetime.now().hour) + \":\" + str(datetime.datetime.now().minute))\n",
    "    \n",
    "    # open up a folder corresponding to the hand gesture\n",
    "    letter_folder_path = os.path.join(images_path, image_folders[i])\n",
    "    folder_imgs = os.listdir(letter_folder_path)\n",
    "\n",
    "    # open up each image in the subfolder and save data/labels\n",
    "    for img in range(0, len(folder_imgs), SKIP_VAL):\n",
    "        # read raw image\n",
    "        image_path = os.path.join(letter_folder_path, folder_imgs[img])\n",
    "        temp_data = cv2.imread(image_path)\n",
    "\n",
    "        # resize to 128x128\n",
    "        mod_img = cv2.resize(temp_data, (128, 128), cv2.INTER_LINEAR)\n",
    "        \n",
    "        # apply brightness and contrast, convert to grayscale\n",
    "        brightness = random.randint(-50, 50)\n",
    "        contrast = random.uniform(0.8, 1.2)\n",
    "        mod_img = mod_img.astype(np.float32)  # convert to float32 for operations\n",
    "        mod_img = cv2.addWeighted(mod_img, contrast, np.zeros(mod_img.shape, mod_img.dtype), 0, brightness)\n",
    "        mod_img = cv2.cvtColor(mod_img, cv2.COLOR_BGR2GRAY)\n",
    "        mod_img = mod_img[..., np.newaxis]  # adds a channel dimension\n",
    "        \n",
    "        # Assign the modified image to the pre-allocated array\n",
    "        image_data[index] = mod_img.astype(np.float16)\n",
    "        labels.append(np.float16(i)) #number corresponding to image folder currently open\n",
    "        index += 1  # Increment the index for the next image\n",
    "        \n",
    "        # apply and save horizontal flip\n",
    "        mod_img_flip = cv2.flip(mod_img, 1)\n",
    "        mod_img_flip = mod_img_flip[..., np.newaxis]\n",
    "        image_data[index] = mod_img_flip.astype(np.float16)\n",
    "        labels.append(np.float16(i))\n",
    "        index += 1\n",
    "        \n",
    "        # apply some random rotation (2 images for original and 2 for flipped) and save\n",
    "        pos_rot = random.randint(5, 30)\n",
    "        neg_rot = random.randint(-30, -5)\n",
    "        (h, w) = mod_img.shape[:2]\n",
    "        (ctrX, ctrY) = (h // 2, w // 2)\n",
    "        pos_rot_mat = cv2.getRotationMatrix2D((ctrX, ctrY), pos_rot, 1.0)\n",
    "        neg_rot_mat = cv2.getRotationMatrix2D((ctrX, ctrY), neg_rot, 1.0)\n",
    "        \n",
    "        orig_pos_rot_img = cv2.warpAffine(mod_img, pos_rot_mat, (w, h))\n",
    "        orig_neg_rot_img = cv2.warpAffine(mod_img, neg_rot_mat, (w, h))\n",
    "        flip_pos_rot_img = cv2.warpAffine(mod_img_flip, pos_rot_mat, (w, h))\n",
    "        flip_neg_rot_img = cv2.warpAffine(mod_img_flip, neg_rot_mat, (w, h))\n",
    "        \n",
    "        # Assign the rotated images to the pre-allocated array\n",
    "        orig_pos_rot_img = orig_pos_rot_img[..., np.newaxis]\n",
    "        image_data[index] = orig_pos_rot_img.astype(np.float16)\n",
    "        labels.append(np.float16(i))\n",
    "        index += 1\n",
    "        \n",
    "        orig_neg_rot_img = orig_neg_rot_img[..., np.newaxis]\n",
    "        image_data[index] = orig_neg_rot_img.astype(np.float16)\n",
    "        labels.append(np.float16(i))\n",
    "        index += 1\n",
    "        \n",
    "        flip_pos_rot_img = flip_pos_rot_img[..., np.newaxis]\n",
    "        image_data[index] = flip_pos_rot_img.astype(np.float16)\n",
    "        labels.append(np.float16(i))\n",
    "        index += 1\n",
    "        \n",
    "        flip_neg_rot_img = flip_neg_rot_img[..., np.newaxis]\n",
    "        image_data[index] = flip_neg_rot_img.astype(np.float16)\n",
    "        labels.append(np.float16(i))\n",
    "        index += 1\n",
    "        \n",
    "        del temp_data, mod_img, mod_img_flip, orig_neg_rot_img, orig_pos_rot_img, flip_neg_rot_img, flip_pos_rot_img\n",
    "\n",
    "print(f\"Length of image_data array: {len(image_data)}\")\n",
    "print(f\"Length of labels list: {len(labels)}\")\n",
    "print(\"28 folders times 1500 images times 6 augmentations in each folder equals: \" + str(NUM_CLASSES * 3000//SKIP_VAL * 6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate one image to ensure processing looks correct \n",
    "plt.imshow(image_data[2000].squeeze(), cmap='gray')\n",
    "plt.title(f\"Label: {labels[2000]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure image data and labels are all float16\n",
    "for i in range(len(image_data)):\n",
    "    if image_data[i].dtype != \"float16\":\n",
    "        print(image_data[i].dtype, i)\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    if labels[i].dtype != \"float16\":\n",
    "        print(labels[i].dtype, i)\n",
    "\n",
    "#PyTorch requires color channels to be swapped for the image data\n",
    "image_data = np.transpose(image_data, (0, 3, 1, 2))\n",
    "print(image_data.shape)\n",
    "\n",
    "#check the number of each label that was imported to make sure it is even\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert image_data and labels to tensors\n",
    "image_data_tens = []\n",
    "\n",
    "for i in image_data:\n",
    "  t = torch.from_numpy(i)\n",
    "  image_data_tens.append(t)\n",
    "\n",
    "#Loop to transform numpy data to tensor\n",
    "label_tens = []\n",
    "\n",
    "for i in labels:\n",
    "  t = torch.from_numpy(np.array(i))\n",
    "  label_tens.append(t)\n",
    "\n",
    "print(type(label_tens[1]))\n",
    "print(type(image_data_tens[0]))\n",
    "\n",
    "del image_data #can delete this now that we have tensors, but need to keep labels for reference in calculating accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare to Run the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup training and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data contains: {0.0: 726, 1.0: 733, 2.0: 710, 3.0: 700, 4.0: 709, 5.0: 730, 6.0: 723, 7.0: 725, 8.0: 720, 9.0: 699, 10.0: 717, 11.0: 723, 12.0: 701, 13.0: 719, 14.0: 737, 15.0: 748, 16.0: 710, 17.0: 736, 18.0: 702, 19.0: 709, 20.0: 727, 21.0: 719, 22.0: 738, 23.0: 718, 24.0: 719, 25.0: 732, 26.0: 726, 27.0: 704}\n",
      "test data contains: {0.0: 174, 1.0: 167, 2.0: 190, 3.0: 200, 4.0: 191, 5.0: 170, 6.0: 177, 7.0: 175, 8.0: 180, 9.0: 201, 10.0: 183, 11.0: 177, 12.0: 199, 13.0: 181, 14.0: 163, 15.0: 152, 16.0: 190, 17.0: 164, 18.0: 198, 19.0: 191, 20.0: 173, 21.0: 181, 22.0: 162, 23.0: 182, 24.0: 181, 25.0: 168, 26.0: 174, 27.0: 196}\n",
      "Train set samples: 20160\n",
      "Test set samples: 5040\n"
     ]
    }
   ],
   "source": [
    "#Split dataset into training and test sets\n",
    "x_Train, x_Test, y_Train, y_Test = train_test_split(image_data_tens, label_tens, random_state=42, shuffle=True, test_size=0.2)\n",
    "unique, counts = np.unique(y_Train, return_counts=True)\n",
    "print(\"train data contains: \" + str(dict(zip(unique, counts))))\n",
    "unique, counts = np.unique(y_Test, return_counts=True)\n",
    "print(\"test data contains: \"+ str(dict(zip(unique, counts))))\n",
    "print(\"Train set samples: \"+ str(len(y_Train)))\n",
    "print(\"Test set samples: \"+ str(len(y_Test)))\n",
    "\n",
    "train_data = list(zip(x_Train, y_Train))\n",
    "test_data = list(zip(x_Test, y_Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "del image_data_tens, label_tens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "train_batch_size = 64 \n",
    "test_batch_size = 128\n",
    "learning_rate = 0.001\n",
    "conv_kernel_size = 5\n",
    "pool_kernel_size = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data into DataLoader objects for training/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sampler for train and test data\n",
    "train_sampler = torch.randperm(len(train_data))\n",
    "test_sampler = torch.randperm(len(test_data))\n",
    "\n",
    "# Convert the output of torch.randperm to a CPU tensor (needs to be CPU for this)\n",
    "train_sampler = train_sampler.cpu()\n",
    "test_sampler = test_sampler.cpu()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size = train_batch_size, shuffle = False, sampler=train_sampler, num_workers = 24, pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size = test_batch_size, shuffle=False, sampler=test_sampler, num_workers = 24, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "  #__init__: Construct the layers in the model\n",
    "  def __init__(self):\n",
    "    super(CNN, self).__init__()\n",
    "\n",
    "    # Convolutional layers\n",
    "    self.conv1 = nn.Conv2d(1, 8, conv_kernel_size, padding=2, stride=1)\n",
    "    self.conv2 = nn.Conv2d(8, 16, conv_kernel_size, padding=2, stride=1)\n",
    "    self.conv3 = nn.Conv2d(16, 32, conv_kernel_size, padding=2, stride=1)\n",
    "    self.conv4 = nn.Conv2d(32, 64, conv_kernel_size, padding=2, stride=1)\n",
    "    self.conv5 = nn.Conv2d(64, 128, conv_kernel_size, padding=2, stride=1)\n",
    "\n",
    "    # Pooling layer\n",
    "    self.pool = nn.MaxPool2d(pool_kernel_size)\n",
    "\n",
    "    # Calculate the size of the flattened tensor after the convolution and pooling layers\n",
    "    self.flattened_size = 128 * (128 // (pool_kernel_size ** 3)) * (128 // (pool_kernel_size ** 3)) \n",
    "\n",
    "    # Fully connected layers\n",
    "    self.fc1 = nn.Linear(self.flattened_size, 64)\n",
    "    self.out = nn.Linear(64, 28)\n",
    "\n",
    "    # Activation function layer\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "    # Flatten layer\n",
    "    self.flatten = nn.Flatten()\n",
    "\n",
    "    # Dropout layers\n",
    "    self.fc_drop = nn.Dropout(p=0.4)\n",
    "\n",
    "    # Batch normalization layers (need unique ones for each size of layer)\n",
    "    self.conv1_bn = nn.BatchNorm2d(8, affine=True)  # affine = True makes it learnable\n",
    "    self.conv2_bn = nn.BatchNorm2d(16, affine=True)\n",
    "    self.conv3_bn = nn.BatchNorm2d(32, affine=True)\n",
    "    self.conv4_bn = nn.BatchNorm2d(64, affine=True)\n",
    "    self.conv5_bn = nn.BatchNorm2d(128, affine=True)\n",
    "    self.fc1_bn = nn.BatchNorm1d(64, affine=True)\n",
    "\n",
    "  # forward: setup the layer order (forward pass)\n",
    "  def forward(self, x):\n",
    "\n",
    "    # First conv layer\n",
    "    x = self.conv1(x)\n",
    "    x = self.conv1_bn(x)\n",
    "    x = self.relu(x)\n",
    "\n",
    "    # Second conv & pooling layer\n",
    "    x = self.conv2(x)\n",
    "    x = self.conv2_bn(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    # Third conv layer\n",
    "    x = self.conv3(x)\n",
    "    x = self.conv3_bn(x)\n",
    "    x = self.relu(x)\n",
    "\n",
    "    # Fourth conv layer and pool\n",
    "    x = self.conv4(x)\n",
    "    x = self.conv4_bn(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    # FouFifthrth conv layer and pool\n",
    "    x = self.conv5(x)\n",
    "    x = self.conv5_bn(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "    \n",
    "    # Flatten input and feed to fully connected layers\n",
    "    x = self.flatten(x)\n",
    "    x = self.fc1(x)\n",
    "    x = self.fc1_bn(x)\n",
    "    x = self.fc_drop(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.out(x)\n",
    "    output = x\n",
    "\n",
    "    # nn.CrossEntropyLoss() expects raw logits, so the softmax is included in the loss function.\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate a CNN model consructed above\n",
    "cnn_model = CNN()\n",
    "cnn_model.to(device) #move model to CUDA\n",
    "\n",
    "#Print CNN model to view layers (only layer structure seen, not in forward defined format)\n",
    "print(cnn_model)\n",
    "\n",
    "#View summary of model (with full forward defined structure) and see all parameters\n",
    "torchsummary.summary(cnn_model, input_size=(1, 128, 128))\n",
    "#check model is assigned to cuda\n",
    "print(next(cnn_model.parameters()).device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model, evaluate on test set and save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the loss function and optimizer\n",
    "#should try an adjustable loss function eventually\n",
    "cnn_model = cnn_model.to(device)\n",
    "loss_f = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassAccuracy(preds, labels):\n",
    "    preds = np.array(preds)\n",
    "    labels = np.array(labels)\n",
    "    classes = np.unique(np.array(labels, dtype=int)) #make keys ints \n",
    "    class_accuracies = {}\n",
    "\n",
    "    for c in classes:\n",
    "        indicies = np.where(labels == c)[0]  #Get indices where label == c\n",
    "        correct = np.sum(preds[indicies] == labels[indicies])\n",
    "        total = len(indicies)\n",
    "        class_accuracies[c] = (correct / total) if total > 0 else 0.0  # Avoid division by zero\n",
    "\n",
    "    return class_accuracies\n",
    "\n",
    "def averageAccuracy(preds, labels):\n",
    "    preds = np.array(preds)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    correct = np.sum(preds[:] == labels[:])\n",
    "    total = len(preds)\n",
    "    accuracy = (correct / total) if total > 0 else 0.0\n",
    "    return accuracy\n",
    "\n",
    "def classF1Score(preds, labels):\n",
    "    score_array = sklearn.metrics.f1_score(labels, preds, average=None) \n",
    "    ave_f1_score = np.mean(score_array)  \n",
    "    class_max = np.argmax(score_array)  \n",
    "    class_min = np.argmin(score_array)  \n",
    "    best_class_f1_score = np.max(score_array)\n",
    "    worst_class_f1_score = np.min(score_array)\n",
    "    \n",
    "    return ave_f1_score, class_max, best_class_f1_score, class_min, worst_class_f1_score, score_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = []\n",
    "test_accuracy = []\n",
    "test_f1_score = []\n",
    "max_acc_class = []\n",
    "best_class_acc = []\n",
    "min_acc_class = []\n",
    "worst_class_acc = []\n",
    "max_f1_class = []\n",
    "best_class_f1 = []\n",
    "min_f1_class = []\n",
    "worst_class_f1 = []\n",
    "last_class_f1_score_array = []\n",
    "last_class_accuracy_array = []\n",
    "\n",
    "def test(model):\n",
    "    #put the model into eval mode to disable grads and learning\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_total_samples = len(test_loader.dataset)\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        #Loop for testing image predictions vs labels\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device).long()  # Convert labels to long (int64) for CrossEntropyLoss\n",
    "            outputs = model(images.float())\n",
    "            probs = torch.softmax(outputs, dim=1)  # Convert logits to probabilities\n",
    "            preds = torch.argmax(probs, dim=1)  # Get predicted class labels\n",
    "            loss = loss_f(outputs, labels.long())\n",
    "            n_correct += (preds == labels).sum().item()\n",
    "            all_predictions.append(preds.tolist())\n",
    "            all_labels.append(labels.tolist())\n",
    "        \n",
    "        #flatten lists to be just one list so we can get accuracy metrics\n",
    "        all_predictions = [item for sublist in all_predictions for item in sublist]\n",
    "        all_labels = [item for sublist in all_labels for item in sublist]\n",
    "        #calculate and store metrics\n",
    "        loss = loss_f(outputs, labels)\n",
    "        test_loss.append(loss.item())\n",
    "        class_accuracies = getClassAccuracy(np.array(all_predictions), np.array(all_labels))\n",
    "        last_class_accuracy_array.append(class_accuracies)\n",
    "        best_class = max(class_accuracies, key=class_accuracies.get)\n",
    "        worst_class = min(class_accuracies, key=class_accuracies.get)\n",
    "        max_acc_class.append(best_class)\n",
    "        best_class_acc.append(class_accuracies[best_class])\n",
    "        min_acc_class.append(worst_class)\n",
    "        worst_class_acc.append(class_accuracies[worst_class])\n",
    "        ave_accuracy = averageAccuracy(np.array(all_predictions), np.array(all_labels))\n",
    "        test_accuracy.append(ave_accuracy)\n",
    "        ave_f1_score, f1_class_max, best_class_f1_score, f1_class_min, worst_class_f1_score, score_array = classF1Score(np.array(all_predictions), np.array(all_labels))\n",
    "        last_class_f1_score_array.append(score_array)\n",
    "        test_f1_score.append(ave_f1_score)\n",
    "        max_f1_class.append(f1_class_max)\n",
    "        best_class_f1.append(best_class_f1_score)\n",
    "        min_f1_class.append(f1_class_min)\n",
    "        worst_class_f1.append(worst_class_f1_score)\n",
    "        print(f\"Test loss: {test_loss[-1]}\") \n",
    "        print(f\"Test average accuracy: {test_accuracy[-1]:.4f}, Max accuracy class: {max_acc_class[-1]} with {best_class_acc[-1]:.2f}, Min accuracy class: {min_acc_class[-1]} with {worst_class_acc[-1]:.2f}\")\n",
    "        print(f\"Test average F1 score: {test_f1_score[-1]:.4f}, Max f1 class: {max_f1_class[-1]} with {best_class_f1[-1]:.2f}, Min f1 class: {min_f1_class[-1]} with {worst_class_f1[-1]:.2f}\")\n",
    "    #put the model back in train mode\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total_steps = len(train_loader)\n",
    "training_loss = []\n",
    "training_accuracy = []\n",
    "\n",
    "# Loop iterates over the number of epochs specified\n",
    "for epoch in range(n_epochs):\n",
    "  cnn_model.train() \n",
    "\n",
    "  # Loop iterates over the training loader\n",
    "  for i, (images, labels) in enumerate(train_loader):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device).long()\n",
    "    \n",
    "    # Forward pass and loss calculation\n",
    "    outputs = cnn_model(images.float())\n",
    "    probs = torch.softmax(outputs, dim=1)  # Convert output logits to probabilities\n",
    "    preds = torch.argmax(probs, dim=1)  # Get predicted class labels\n",
    "    loss = loss_f(outputs, labels)\n",
    "\n",
    "    # Backward path and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every batch size updates to visualize training\n",
    "    if (i + 1) % n_total_steps == 0:\n",
    "      print(f'Epoch [{epoch + 1}/{n_epochs}], Step [{i + 1}/{n_total_steps}], Loss: {loss.item():.4f}, Time: {datetime.datetime.now().hour}:{datetime.datetime.now().minute}')\n",
    "\n",
    "  training_loss.append(loss.item())\n",
    "  train_acc = averageAccuracy(preds.cpu().numpy(), labels.cpu().numpy())\n",
    "  training_accuracy.append(train_acc)\n",
    "  test(cnn_model)  # run the test dataset each epoch iteration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the metrics for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===============================================\")\n",
    "print(\"TEST EVALUATION RESULTS\")\n",
    "print(\"===============================================\")\n",
    "print(\"Final Training Loss: \" + str(training_loss[-1])) \n",
    "print(\"Overall Test Loss: \" + str(test_loss[-1]))\n",
    "print(\"Overall Test Accuracy: \" + str(test_accuracy[-1]*100) + \"%\")\n",
    "print(\"Macro F1 Score: \" + str(test_f1_score[-1]))\n",
    "print(\"===============================================\")\n",
    "print(\"CLASS PERFORMANCE BREAKDOWN\")\n",
    "print(\"===============================================\")\n",
    "print(f\"Best performing class (accuracy): Class {max_acc_class[-1]} with {best_class_acc[-1]*100:2f}% accuracy\")\n",
    "print(f\"Worst performing class (accuracy): Class {(min_acc_class[-1])} with {(worst_class_acc[-1]*100):2f}% accuracy\")\n",
    "print(f\"Best performing class (F1): Class {(max_f1_class[-1])} with {(best_class_acc[-1]):2f} F1 score\")\n",
    "print(f\"Worst performing class (F1): Class {(min_f1_class[-1])} with {(worst_class_acc[-1]):2f} F1 score\")\n",
    "print(\"===============================================\")\n",
    "\n",
    "class_accuracy_data = list(last_class_accuracy_array[-1].values())\n",
    "class_f1_data = last_class_f1_score_array[-1]\n",
    "\n",
    "#get all labels from the dataset so I can pull unique values later\n",
    "all_labels = []\n",
    "for _, labels in train_loader:  \n",
    "    all_labels.extend(labels.numpy())  \n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "#make a loss plot\n",
    "plt.figure()\n",
    "plt.plot(test_loss, label=\"Test Loss\")\n",
    "plt.plot(training_loss, label=\"Training Loss\")\n",
    "plt.title(\"Training vs Test Loss over Epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#make an accuracy plot\n",
    "plt.figure()\n",
    "plt.plot(test_accuracy, label=\"Test Accuracy\")\n",
    "plt.plot(training_accuracy, label=\"Training Accuracy\")\n",
    "plt.title(\"Model Accuracy Over Epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#Make a class performance plot\n",
    "plt.figure()\n",
    "x = np.arange(len(np.unique(all_labels))) * 5 # X locations for the groups\n",
    "width = 1.5  # Width of the bars\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.bar(x - width/2, class_accuracy_data, width, label='Accuracy')\n",
    "ax.bar(x + width/2, class_f1_data, width, label='F1 Score')\n",
    "# Labels, title, and legend\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(np.unique(all_labels).astype(int))\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_ylabel('Performance')\n",
    "ax.set_title('Per-Class Performance (Final Epoch)')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
